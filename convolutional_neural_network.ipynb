{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1sLPOKIMizj-Mgdzoj9xoGn5dmkIIejyK",
      "authorship_tag": "ABX9TyMjyfo8FMrMa2NSdoBr/GA1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minhajul99/CNN/blob/main/convolutional_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network"
      ],
      "metadata": {
        "id": "grm8QzelxZGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the libraries"
      ],
      "metadata": {
        "id": "YKxc6k7wxaVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ],
      "metadata": {
        "id": "KshcrpSCyt-O"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "i1XxW80AxTAb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5xueD7eR1ol-",
        "outputId": "c4a93163-2392-45d4-da73-a25f3cac180e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.17.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unziping the data\n"
      ],
      "metadata": {
        "id": "7nF8GQMhzcr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/drive/MyDrive/Dog_0r_Cat/Data.zip -d /content/drive/MyDrive/Dog_0r_Cat/"
      ],
      "metadata": {
        "id": "jgkzsvydzg9k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 - Data Preprocessing"
      ],
      "metadata": {
        "id": "LkR6T5Ge1tq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 64\n",
        "img_width = 64"
      ],
      "metadata": {
        "id": "RltBbxCs4iSP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Training set"
      ],
      "metadata": {
        "id": "6CkRKISa1us0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  '/content/drive/MyDrive/Dog_0r_Cat/dataset/training_set',\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX_jOGBD1yWd",
        "outputId": "959d68f2-1730-4bb8-926f-62025ee42e0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 files belonging to 2 classes.\n",
            "Using 6400 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Test set"
      ],
      "metadata": {
        "id": "SYPGbnA_4W0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  '/content/drive/MyDrive/Dog_0r_Cat/dataset/test_set',\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klPRy5II4cGF",
        "outputId": "1e6d230b-c864-4d77-8487-594d2227ba25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Using 400 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2 - Building the CNN"
      ],
      "metadata": {
        "id": "HSPDflC594zR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialising the CNN"
      ],
      "metadata": {
        "id": "ksm-RGsP94v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "R4N5c99O989Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 - Convolution"
      ],
      "metadata": {
        "id": "Dr-1rr7d-E9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CqlVr-n-Iyi",
        "outputId": "8209631e-a51a-4b38-9083-9438aa360a95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 - Pooling"
      ],
      "metadata": {
        "id": "2tkG8pid-eye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "6QSPD-Gs-fjI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a second convolutional layer"
      ],
      "metadata": {
        "id": "e1E2EFZU-2d1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "Imlz_nDQ-3ES"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 - Flattening"
      ],
      "metadata": {
        "id": "vKl3BGqD_C2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "MTSN66h0_DiK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 - Full Connection"
      ],
      "metadata": {
        "id": "w-bytRCI_CzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "wn5us6X0_SR8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5 - Output Layer"
      ],
      "metadata": {
        "id": "OfOr3zB9_YOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "T0Z7Sgq0_X98"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 - Training the CNN"
      ],
      "metadata": {
        "id": "cca7O5_k_evs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the CNN"
      ],
      "metadata": {
        "id": "VxoghVHB_f6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "aS_EBKLa_ix2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ],
      "metadata": {
        "id": "gwjHte5A_n24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = train_ds, validation_data = test_ds, epochs = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32zYAYm8_ouY",
        "outputId": "1f78dd9f-923b-4670-b30d-d8e5de5c5ff6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1795s\u001b[0m 9s/step - accuracy: 0.5054 - loss: 13.7580 - val_accuracy: 0.5250 - val_loss: 0.6896\n",
            "Epoch 2/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 105ms/step - accuracy: 0.5749 - loss: 0.6643 - val_accuracy: 0.5075 - val_loss: 0.6977\n",
            "Epoch 3/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 106ms/step - accuracy: 0.6153 - loss: 0.6141 - val_accuracy: 0.5350 - val_loss: 0.7391\n",
            "Epoch 4/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 103ms/step - accuracy: 0.6637 - loss: 0.5570 - val_accuracy: 0.5250 - val_loss: 0.8000\n",
            "Epoch 5/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 99ms/step - accuracy: 0.7168 - loss: 0.4772 - val_accuracy: 0.5675 - val_loss: 0.9814\n",
            "Epoch 6/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 106ms/step - accuracy: 0.7567 - loss: 0.4268 - val_accuracy: 0.5500 - val_loss: 1.1144\n",
            "Epoch 7/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 106ms/step - accuracy: 0.7833 - loss: 0.3933 - val_accuracy: 0.5700 - val_loss: 1.2013\n",
            "Epoch 8/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 103ms/step - accuracy: 0.8121 - loss: 0.3666 - val_accuracy: 0.5275 - val_loss: 1.3571\n",
            "Epoch 9/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 102ms/step - accuracy: 0.8338 - loss: 0.3204 - val_accuracy: 0.5850 - val_loss: 1.3120\n",
            "Epoch 10/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 105ms/step - accuracy: 0.8586 - loss: 0.2848 - val_accuracy: 0.5775 - val_loss: 1.2999\n",
            "Epoch 11/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 108ms/step - accuracy: 0.8679 - loss: 0.2715 - val_accuracy: 0.5950 - val_loss: 1.4569\n",
            "Epoch 12/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 107ms/step - accuracy: 0.8958 - loss: 0.2155 - val_accuracy: 0.5975 - val_loss: 1.7495\n",
            "Epoch 13/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 108ms/step - accuracy: 0.9022 - loss: 0.2079 - val_accuracy: 0.5700 - val_loss: 1.8739\n",
            "Epoch 14/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 110ms/step - accuracy: 0.8859 - loss: 0.2630 - val_accuracy: 0.5950 - val_loss: 1.8896\n",
            "Epoch 15/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 108ms/step - accuracy: 0.9047 - loss: 0.2160 - val_accuracy: 0.6050 - val_loss: 1.5813\n",
            "Epoch 16/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 102ms/step - accuracy: 0.9188 - loss: 0.1826 - val_accuracy: 0.5725 - val_loss: 1.9640\n",
            "Epoch 17/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - accuracy: 0.9346 - loss: 0.1558 - val_accuracy: 0.5925 - val_loss: 1.8625\n",
            "Epoch 18/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 101ms/step - accuracy: 0.9434 - loss: 0.1283 - val_accuracy: 0.6075 - val_loss: 2.1510\n",
            "Epoch 19/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - accuracy: 0.9395 - loss: 0.1487 - val_accuracy: 0.6075 - val_loss: 2.0792\n",
            "Epoch 20/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 116ms/step - accuracy: 0.9344 - loss: 0.1655 - val_accuracy: 0.5700 - val_loss: 2.1702\n",
            "Epoch 21/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 115ms/step - accuracy: 0.9457 - loss: 0.1435 - val_accuracy: 0.5800 - val_loss: 2.2240\n",
            "Epoch 22/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 109ms/step - accuracy: 0.9599 - loss: 0.0998 - val_accuracy: 0.5625 - val_loss: 2.9509\n",
            "Epoch 23/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 103ms/step - accuracy: 0.9443 - loss: 0.1451 - val_accuracy: 0.5675 - val_loss: 3.0198\n",
            "Epoch 24/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 99ms/step - accuracy: 0.9452 - loss: 0.1615 - val_accuracy: 0.5850 - val_loss: 2.6114\n",
            "Epoch 25/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 105ms/step - accuracy: 0.9510 - loss: 0.1285 - val_accuracy: 0.5600 - val_loss: 2.4266\n",
            "Epoch 26/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - accuracy: 0.9649 - loss: 0.0946 - val_accuracy: 0.5900 - val_loss: 2.9547\n",
            "Epoch 27/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 108ms/step - accuracy: 0.9635 - loss: 0.0977 - val_accuracy: 0.5775 - val_loss: 2.6315\n",
            "Epoch 28/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 111ms/step - accuracy: 0.9603 - loss: 0.1204 - val_accuracy: 0.5525 - val_loss: 2.7403\n",
            "Epoch 29/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 105ms/step - accuracy: 0.9701 - loss: 0.0746 - val_accuracy: 0.5775 - val_loss: 2.9253\n",
            "Epoch 30/30\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 103ms/step - accuracy: 0.9693 - loss: 0.0846 - val_accuracy: 0.5750 - val_loss: 3.2597\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x787ff15e67a0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4 - Making a single prediction"
      ],
      "metadata": {
        "id": "-qc-lAYiLk5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/drive/MyDrive/Dog_0r_Cat/dataset/single_prediction/cat_or_dog_2.jpg'\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    img_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = cnn.predict(img_array)\n",
        "\n",
        "if predictions[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unOJNrrVMMOx",
        "outputId": "a199bab6-58be-41ba-9bcf-01af958d0ab7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LwnPYLENIHr",
        "outputId": "80b17c9b-6ad8-4f65-975f-b580d0032acc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n"
          ]
        }
      ]
    }
  ]
}